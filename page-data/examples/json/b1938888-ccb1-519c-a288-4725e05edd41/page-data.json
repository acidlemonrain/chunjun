{"componentChunkName":"component---src-pages-examples-json-json-content-parent-file-id-jsx","path":"/examples/json/b1938888-ccb1-519c-a288-4725e05edd41/","result":{"data":{"jsonContent":{"id":"c96e31eb-c809-5a72-a8f2-f8d2dc047c5b","content":"CREATE TABLE source\n(\n    id          bigint,\n    user_id     bigint,\n    name        STRING\n) WITH (\n      'connector' = 'mysql-x',\n      'url' = 'jdbc:mysql://ip:3308/tudou?useSSL=false',\n      'table-name' = 'kudu1',\n      'username' = 'username',\n      'password' = 'password'\n      ,'scan.fetch-size' = '2'\n      ,'scan.query-timeout' = '10'\n\n      ,'scan.polling-interval' = '3000' --间隔轮训时间。非必填(不填为离线任务)，无默认\n\n      ,'scan.parallelism' = '3' -- 并行度\n--       ,'scan.fetch-size' = '2' -- 每次从数据库中fetch大小。默认：1024条\n--       ,'scan.query-timeout' = '10' -- 数据库连接超时时间。默认：不超时\n\n      ,'scan.partition.column' = 'id' -- 多并行度读取的切分字段，多并行度下必需要设置。无默认\n      ,'scan.partition.strategy' = 'mod' -- 数据分片策略。默认：range，如果并行度大于1，且是增量任务或者间隔轮询，则会使用mod分片\n\n      ,'scan.increment.column' = 'id' -- 增量字段名称，必须是表中的字段。非必填，无默认\n--       ,'scan.increment.column-type' = 'int'  -- 增量字段类型。非必填，无默认\n      ,'scan.start-location' = '100' -- 增量字段开始位置,如果不指定则先同步所有，然后在增量。非必填，无默认，如果没配置scan.increment.column，则不生效\n\n      ,'scan.restore.columnname' = 'id' -- 开启了cp，任务从sp/cp续跑字段名称。如果续跑，则会覆盖scan.start-location开始位置，从续跑点开始。非必填，无默认\n--       ,'scan.restore.columntype' = 'int' -- 开启了cp，任务从sp/cp续跑字段类型。非必填，无默认\n      );\n\nCREATE TABLE sink\n(\n    id bigint,\n    user_id bigint,\n    name string\n) WITH (\n      'connector' = 'hdfs-x'\n      ,'path' = 'hdfs://ns/user/hive/warehouse/tudou.db/kudu_txt'\n      ,'fileName' = 'pt=1'\n      ,'properties.hadoop.user.name' = 'root'\n      ,'properties.dfs.ha.namenodes.ns' = 'nn1,nn2'\n      ,'properties.fs.defaultFS' = 'hdfs://ns'\n      ,'properties.dfs.namenode.rpc-address.ns.nn2' = 'ip:9000'\n      ,'properties.dfs.client.failover.proxy.provider.ns' = 'org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider'\n      ,'properties.dfs.namenode.rpc-address.ns.nn1' = 'ip:9000'\n      ,'properties.dfs.nameservices' = 'ns'\n      ,'properties.fs.hdfs.impl.disable.cache' = 'true'\n      ,'properties.fs.hdfs.impl' = 'org.apache.hadoop.hdfs.DistributedFileSystem'\n      ,'defaultFS' = 'hdfs://ns'\n      ,'fieldDelimiter' = ','\n      ,'encoding' = 'utf-8'\n      ,'maxFileSize' = '10485760'\n      ,'nextCheckRows' = '20000'\n      ,'writeMode' = 'overwrite'\n      ,'fileType' = 'text'\n\n      ,'sink.parallelism' = '3'\n      );\n\ninsert into sink\nselect *\nfrom source u;\n"}},"pageContext":{"id":"c96e31eb-c809-5a72-a8f2-f8d2dc047c5b","parent__id":"b1938888-ccb1-519c-a288-4725e05edd41","__params":{"parent__id":"b1938888-ccb1-519c-a288-4725e05edd41"}}},"staticQueryHashes":["1197112220","1410458087","527733040","63159454"]}