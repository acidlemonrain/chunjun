{"componentChunkName":"component---src-pages-examples-json-json-content-parent-file-id-jsx","path":"/examples/json/b1106b22-05b7-57db-b226-995920ab630d/","result":{"data":{"jsonContent":{"id":"1c8ebef5-28d2-504e-a55a-2cbfadf95aed","content":"-- {\"id\":100,\"name\":\"lb james阿道夫\",\"money\":293.899778,\"dateone\":\"2020-07-30 10:08:22\",\"age\":\"33\",\"datethree\":\"2020-07-30 10:08:22.123\",\"datesix\":\"2020-07-30 10:08:22.123456\",\"datenigth\":\"2020-07-30 10:08:22.123456789\",\"dtdate\":\"2020-07-30\",\"dttime\":\"10:08:22\"}\nCREATE TABLE source_ods_fact_user_ippv (\n    id INT\n    , name STRING\n    , money decimal\n    , dateone timestamp\n    , age bigint\n    , datethree timestamp\n    , datesix timestamp(6)\n    , datenigth timestamp(9)\n    , dtdate date\n    , dttime time\n\n    , `partition` BIGINT METADATA VIRTUAL -- from Kafka connector\n    , `topic` STRING METADATA VIRTUAL -- from Kafka connector\n    , `leader-epoch` int METADATA VIRTUAL -- from Kafka connector\n    , `offset` BIGINT METADATA VIRTUAL  -- from Kafka connector\n    , ts TIMESTAMP(3) METADATA FROM 'timestamp' -- from Kafka connector\n    , `timestamp-type` STRING METADATA VIRTUAL  -- from Kafka connector\n    , partition_id BIGINT METADATA FROM 'partition' VIRTUAL   -- from Kafka connector\n\n    , WATERMARK FOR datethree AS datethree - INTERVAL '5' SECOND\n) WITH (\n      'connector' = 'kafka-x'\n      ,'topic' = 'user_behavior'\n      ,'properties.bootstrap.servers' = 'localhost:9092'\n      ,'properties.group.id' = 'luna_g'\n      ,'scan.startup.mode' = 'earliest-offset'\n      ,'format' = 'json'\n      ,'json.timestamp-format.standard' = 'SQL'\n      ,'scan.parallelism' = '1'\n      );\n\n\nCREATE TABLE sink\n(\n    id          int,\n    name        varchar,\n    money       decimal,\n    age         bigint,\n    datethree   timestamp,\n    datesix     timestamp\n) WITH (\n       -- 'connector' = 'stream-x'\n\n      'connector' = 'mysql-x',\n      'url' = 'jdbc:mysql://localhost:3306/test',\n      'table-name' = 'flink_type',\n      'username' = 'root',\n      'password' = 'abc123',\n\n      'sink.buffer-flush.max-rows' = '1024', -- 批量写数据条数，默认：1024\n      'sink.buffer-flush.interval' = '10000', -- 批量写时间间隔，默认：10000毫秒\n      'sink.all-replace' = 'true', -- 解释如下(其他rdb数据库类似)：默认：false。定义了PRIMARY KEY才有效，否则是追加语句\n                                  -- sink.all-replace = 'true' 生成如：INSERT INTO `result3`(`mid`, `mbb`, `sid`, `sbb`) VALUES (?, ?, ?, ?) ON DUPLICATE KEY UPDATE `mid`=VALUES(`mid`), `mbb`=VALUES(`mbb`), `sid`=VALUES(`sid`), `sbb`=VALUES(`sbb`) 。会将所有的数据都替换。\n                                  -- sink.all-replace = 'false' 生成如：INSERT INTO `result3`(`mid`, `mbb`, `sid`, `sbb`) VALUES (?, ?, ?, ?) ON DUPLICATE KEY UPDATE `mid`=IFNULL(VALUES(`mid`),`mid`), `mbb`=IFNULL(VALUES(`mbb`),`mbb`), `sid`=IFNULL(VALUES(`sid`),`sid`), `sbb`=IFNULL(VALUES(`sbb`),`sbb`) 。如果新值为null，数据库中的旧值不为null，则不会覆盖。\n      'sink.parallelism' = '1'    -- 写入结果的并行度，默认：null\n      );\n\ninsert into sink\nselect id ,name,money,age,datethree,datesix\nfrom source_ods_fact_user_ippv;\n\n"}},"pageContext":{"id":"1c8ebef5-28d2-504e-a55a-2cbfadf95aed","parent__id":"b1106b22-05b7-57db-b226-995920ab630d","__params":{"parent__id":"b1106b22-05b7-57db-b226-995920ab630d"}}},"staticQueryHashes":["1197112220","1410458087","527733040","63159454"]}